{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mmlu'\n",
    "path_base = '../DATASETS/MMLU/' if dataset == 'mmlu' else '../DATASETS/MMLU_PRO/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_txt(file_path)->str:\n",
    "\n",
    "  with open(file_path, \"r\", encoding=\"Windows-1252\", errors=\"ignore\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "  return content\n",
    "\n",
    "def count_ids(content: str, suffixes=['ins', 'inp', 'out']) -> None:\n",
    "    \"\"\"\n",
    "    Conta IDs com sufixos específicos (ins, inp, out) no conteúdo fornecido.\n",
    "\n",
    "    Args:\n",
    "        content (str): O texto que contém os IDs a serem contados.\n",
    "\n",
    "    Prints:\n",
    "        Contagem de IDs por sufixo e o total de IDs.\n",
    "    \"\"\"\n",
    "  \n",
    "    counts = {}\n",
    "\n",
    "    for suffix in suffixes:\n",
    "        pattern = fr'[\\'\"]ID[\\'\"]:\\s*[\\'\"]\\d+{suffix}[\\'\"]' #     pattern = fr'\"ID\":\\s*\"\\d+{suffix}\"' pega menos id\n",
    "        matches = re.findall(pattern, content)\n",
    "        counts[suffix] = len(matches)\n",
    "        print(f\"Total de IDs com sufixo '{suffix}': {counts[suffix]}\")\n",
    "\n",
    "    total_ids = sum(counts.values())\n",
    "    print(\"Total ids:\", total_ids)\n",
    "\n",
    "\n",
    "# Figurative\n",
    "def extrair_dados_multiplos(texto):\n",
    "    \"\"\"\n",
    "    Extrai dados estruturados de um texto baseado em um padrão de expressão regular,\n",
    "    considerando aspas simples ou duplas nos campos.\n",
    "    \"\"\"\n",
    "    # Padrão ajustado para aceitar aspas simples ou duplas\n",
    "    padrao = re.compile(\n",
    "        r\"[\\'\\\"]ID[\\'\\\"]:\\s*[\\'\\\"]([^\\'\\\"]+)[\\'\\\"]\\s*,\\s*[\\'\\\"]ORIGINAL[\\'\\\"]:\\s*[\\'\\\"](.*?)(?<!\\\\)[\\'\\\"]\\s*,\\s*[\\'\\\"]FIGURATIVO[\\'\\\"]:\\s*(null|[\\'\\\"](.*?)(?<!\\\\)[\\'\\\"])\\s*,\\s*[\\'\\\"]REESCRITO[\\'\\\"]:\\s*(null|[\\'\\\"](.*?)(?<!\\\\)[\\'\\\"])\\s*,\\s*[\\'\\\"]RESULTADO[\\'\\\"]:\\s*[\\'\\\"](.*?)(?<!\\\\)[\\'\\\"]\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    matches = padrao.findall(texto)\n",
    "    resultados = []\n",
    "\n",
    "    for match in matches:\n",
    "        id_val = match[0]\n",
    "        original_val = match[1]\n",
    "        figurativo_val = match[3] if match[2] != 'null' else None\n",
    "        reescrito_val = match[5] if match[4] != 'null' else None\n",
    "        resultado_val = match[6]\n",
    "\n",
    "        resultados.append((id_val, original_val, figurativo_val, reescrito_val, resultado_val))\n",
    "\n",
    "    return resultados\n",
    "\n",
    "def processar_content_para_dataframe_figurative(content):\n",
    "\n",
    "    ids, originais, figurativos, reescritos, resultados = [], [], [], [], []\n",
    "\n",
    "    blocos_dados = content.split(\"json\\n[\\n\")\n",
    "    blocos_dados = [bloco.replace('\\u200b', '').strip() for bloco in blocos_dados]\n",
    "\n",
    "    for bloco in blocos_dados:\n",
    "        conjuntos = extrair_dados_multiplos(bloco)\n",
    "        for id_val, original_val, figurativo_val, reescrito_val, resultado_val in conjuntos:\n",
    "            if id_val and original_val and resultado_val:\n",
    "                ids.append(id_val)\n",
    "                originais.append(original_val)\n",
    "                figurativos.append(figurativo_val)\n",
    "                reescritos.append(reescrito_val)\n",
    "                resultados.append(resultado_val)\n",
    "\n",
    "    df_result = pd.DataFrame({\n",
    "        'ID': ids,\n",
    "        'ORIGINAL': originais,\n",
    "        'FIGURATIVO': figurativos,\n",
    "        'REESCRITO': reescritos,\n",
    "        'RESULTADO': resultados\n",
    "    })\n",
    "\n",
    "    print(f\"DataFrame - shape: {df_result.shape}, IDs únicos: {df_result.ID.nunique()}\")\n",
    "\n",
    "    return df_result\n",
    "\n",
    "## Glosa\n",
    "def glosa_extrair_dados_para_dataframe_by_bucket(content):\n",
    "\n",
    "    blocos_dados = content.split('json\\n[')\n",
    "    blocos_dados = [bloco.replace('\\u200b', '').strip() for bloco in blocos_dados]\n",
    "\n",
    "    dados_extraidos = []\n",
    "\n",
    "    # Função para extrair dados dos novos blocos de texto com colunas ID, PT e GLOSA\n",
    "    def extrair_dados_multiplos(texto):\n",
    "        try:\n",
    "            # Tenta carregar o texto diretamente como JSON, caso ele já esteja em um formato válido\n",
    "            dados = json.loads(texto)\n",
    "            if isinstance(dados, list):  # Verifica se é uma lista de dicionários\n",
    "                return [(item.get(\"ID\"), item.get(\"PT\"), item.get(\"GLOSA\")) for item in dados]\n",
    "        except json.JSONDecodeError:\n",
    "            # Caso falhe em decodificar, utiliza regex para buscar blocos que não estão no formato JSON\n",
    "            padrao = re.compile(\n",
    "                r'\"ID\":\\s*\"([^\"]+)\"\\s*,\\s*\"PT\":\\s*\"(.*?)\"\\s*,\\s*\"(?:GLOSA|GLOSSARY|GLOSE)\":\\s*\"(.*?)\"',\n",
    "                re.DOTALL\n",
    "            )\n",
    "            matches = padrao.findall(texto)\n",
    "            return [(match[0], match[1], match[2] if match[2] != 'null' else None) for match in matches]\n",
    "\n",
    "        return []\n",
    "\n",
    "    # Extrair dados de cada bloco, ignorando o primeiro elemento vazio\n",
    "    for bloco in blocos_dados[1:]:\n",
    "        dados_extraidos.extend(extrair_dados_multiplos(bloco))\n",
    "\n",
    "    # Criar o DataFrame diretamente com a lista de dados extraídos\n",
    "    df = pd.DataFrame(dados_extraidos, columns=['ID', 'PT', 'GLOSA'])\n",
    "    return df\n",
    "\n",
    "def glosa_extrair_dados_para_dataframe_single_block(content):\n",
    "    content = content.replace(\"json\\n\", \"\").strip()\n",
    "    pattern = re.compile(\n",
    "        r\"\\{\\s*'ID':\\s*'([^']+)',\\s*'PT':\\s*'([^']+)',\\s*'GLOSA':\\s*'([^']*)'\\s*\\}\"\n",
    "    )\n",
    "    \n",
    "    dados_extraidos = pattern.findall(content)\n",
    "\n",
    "    df = pd.DataFrame(dados_extraidos, columns=['ID', 'PT', 'GLOSA'])\n",
    "    return df\n",
    "\n",
    "def processar_glosa_to_original_format(df_glosa_response):\n",
    "    aux = df_glosa_response.copy()\n",
    "    aux = aux.astype({'ID': str})\n",
    "\n",
    "    # Extrair ID numérico e TYPE\n",
    "    aux[['ID', 'TYPE']] = aux['ID'].str.extract(r'^(.*?)(Q1|C1|C2|C3|C4|C5|C6|C7|C8|C9|C10)$', expand=True)\n",
    "\n",
    "    aux = aux.astype({'ID': int})\n",
    "    aux = aux.sort_values(by='ID', ascending=True)\n",
    "    print(f\"Resultado glosa---\\n shape: {aux.shape}\\n ids únicos: {aux.ID.nunique()}\")\n",
    "\n",
    "    # Renomear coluna GLOSA para INSTANCE\n",
    "    aux = aux[['ID', 'GLOSA', 'TYPE']].rename(columns={'GLOSA': 'INSTANCE'})\n",
    "\n",
    "    # Mapear valores de TYPE para CLASS_TYPE\n",
    "    type_to_class_map = {f\"C{i}\": f\"C{i}\" for i in range(1, 11)}\n",
    "    type_to_class_map[\"Q1\"] = \"Q1\"\n",
    "    aux['CLASS_TYPE'] = aux['TYPE'].map(type_to_class_map)\n",
    "\n",
    "    # Filtrar valores válidos\n",
    "    aux_valid = aux[aux['CLASS_TYPE'].notna()]\n",
    "\n",
    "    # Reorganizar o DataFrame com pivot_table e lidar com duplicatas\n",
    "    df_final = aux_valid.pivot_table(\n",
    "        index='ID', \n",
    "        columns='CLASS_TYPE', \n",
    "        values='INSTANCE', \n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Ordenar colunas explicitamente\n",
    "    ordered_columns = ['ID', 'Q1'] + [f\"C{i}\" for i in range(1, 11)]\n",
    "    df_final = df_final.reindex(columns=ordered_columns)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame Base para ir para o Figurative --- \n",
      "Shape: (77825, 5) \n",
      "Ids Únicos: 77825 \n",
      "Diferença: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ORIGINAL</th>\n",
       "      <th>TOKENS_EST_ID</th>\n",
       "      <th>TOKENS_EST_ORIGINAL</th>\n",
       "      <th>TOTAL_TOKENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0Q1</td>\n",
       "      <td>Encontre o grau para a extensão de campo dada Q(sqrt(2), sqrt(3), sqrt(18)) sobre Q.</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  \\\n",
       "0  0Q1   \n",
       "\n",
       "                                                                               ORIGINAL  \\\n",
       "0  Encontre o grau para a extensão de campo dada Q(sqrt(2), sqrt(3), sqrt(18)) sobre Q.   \n",
       "\n",
       "   TOKENS_EST_ID  TOKENS_EST_ORIGINAL  TOTAL_TOKENS  \n",
       "0              3                   37            40  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = pd.read_csv(path_base+\"01_\"+dataset+\"_to_figurative.csv\")\n",
    "print(f\"Data Frame Base para ir para o Figurative --- \\nShape: {df_base.shape} \\n\\\n",
    "Ids Únicos: {df_base['ID'].nunique()} \\n\\\n",
    "Diferença: {df_base.shape[0] - df_base['ID'].nunique() }\")\n",
    "df_base.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Figurative Results\n",
    "\n",
    "Ou seja, carrega os responses\n",
    "\n",
    "## Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de IDs com sufixo 'Q1': 10602\n",
      "Total de IDs com sufixo 'C1': 6634\n",
      "Total de IDs com sufixo 'C2': 7006\n",
      "Total de IDs com sufixo 'C3': 7897\n",
      "Total de IDs com sufixo 'C4': 7565\n",
      "Total de IDs com sufixo 'C5': 0\n",
      "Total de IDs com sufixo 'C6': 0\n",
      "Total de IDs com sufixo 'C7': 0\n",
      "Total de IDs com sufixo 'C8': 0\n",
      "Total de IDs com sufixo 'C9': 0\n",
      "Total de IDs com sufixo 'C10': 0\n",
      "Total ids: 39704\n",
      "DataFrame - shape: (39616, 5), IDs únicos: 39582\n",
      "Shape Bucket: (39616, 5)\n",
      "Ids únicos: 39582\n"
     ]
    }
   ],
   "source": [
    "content_bucket = read_file_txt('../DATASETS/METADATA/'+'figurative_'+dataset+'_to_figurative_response.txt')\n",
    "count_ids(content_bucket, suffixes = [\"Q1\", \"C1\", \"C2\", 'C3', \"C4\", \"C5\", \"C6\", 'C7', \"C8\", \"C9\", \"C10\"])\n",
    "\n",
    "df_1 = processar_content_para_dataframe_figurative(content_bucket)\n",
    "print(f\"Shape Bucket: {df_1.shape}\\nIds únicos: {df_1['ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_bucket = read_file_txt('../DATASETS/METADATA/'+'figurative_mmlu_pro_bucket_to_figurative_again_response.txt')\n",
    "#count_ids(content_bucket, suffixes = [\"Q1\", \"C1\", \"C2\", 'C3', \"C4\", \"C5\", \"C6\", 'C7', \"C8\", \"C9\", \"C10\"])\n",
    "\n",
    "#df_2 = processar_content_para_dataframe_figurative(content_bucket)\n",
    "#print(f\" OLD ---\\nShape Bucket: {df_2.shape}\\nIds únicos: {df_2['ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de IDs com sufixo 'Q1': 4853\n",
      "Total de IDs com sufixo 'C1': 8820\n",
      "Total de IDs com sufixo 'C2': 8455\n",
      "Total de IDs com sufixo 'C3': 7586\n",
      "Total de IDs com sufixo 'C4': 7879\n",
      "Total de IDs com sufixo 'C5': 0\n",
      "Total de IDs com sufixo 'C6': 0\n",
      "Total de IDs com sufixo 'C7': 0\n",
      "Total de IDs com sufixo 'C8': 0\n",
      "Total de IDs com sufixo 'C9': 0\n",
      "Total de IDs com sufixo 'C10': 0\n",
      "Total ids: 37593\n",
      "DataFrame - shape: (37503, 5), IDs únicos: 37446\n",
      "Shape Bucket: (37503, 5)\n",
      "Ids únicos: 37446\n"
     ]
    }
   ],
   "source": [
    "content_bucket = read_file_txt(r'C:\\Users\\annap\\Documents\\UFLA\\EVAL\\DATASETS\\METADATA\\figurative_mllu_to_figurative_single_response.txt')\n",
    "count_ids(content_bucket, suffixes = [\"Q1\", \"C1\", \"C2\", 'C3', \"C4\", \"C5\", \"C6\", 'C7', \"C8\", \"C9\", \"C10\"])\n",
    "\n",
    "df_2 = processar_content_para_dataframe_figurative(content_bucket)\n",
    "print(f\"Shape Bucket: {df_2.shape}\\nIds únicos: {df_2['ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de IDs com sufixo 'Q1': 15\n",
      "Total de IDs com sufixo 'C1': 15\n",
      "Total de IDs com sufixo 'C2': 21\n",
      "Total de IDs com sufixo 'C3': 20\n",
      "Total de IDs com sufixo 'C4': 22\n",
      "Total de IDs com sufixo 'C5': 0\n",
      "Total de IDs com sufixo 'C6': 0\n",
      "Total de IDs com sufixo 'C7': 0\n",
      "Total de IDs com sufixo 'C8': 0\n",
      "Total de IDs com sufixo 'C9': 0\n",
      "Total de IDs com sufixo 'C10': 0\n",
      "Total ids: 93\n",
      "DataFrame - shape: (57, 5), IDs únicos: 57\n",
      "Shape Bucket: (57, 5)\n",
      "Ids únicos: 57\n"
     ]
    }
   ],
   "source": [
    "content_single = read_file_txt(r'C:\\Users\\annap\\Documents\\UFLA\\EVAL\\DATASETS\\METADATA\\figurative_last_mllu_to_figurative_single_response.txt')\n",
    "count_ids(content_single, suffixes = [\"Q1\", \"C1\", \"C2\", 'C3', \"C4\", \"C5\", \"C6\", 'C7', \"C8\", \"C9\", \"C10\"])\n",
    "\n",
    "df_3 = processar_content_para_dataframe_figurative(content_single)\n",
    "print(f\"Shape Bucket: {df_3.shape}\\nIds únicos: {df_3['ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figurative results --- \n",
      "Shape: (77176, 5) \n",
      "Ids Únicos: 77084 \n",
      "Diferença: 92\n"
     ]
    }
   ],
   "source": [
    "df_fig = pd.concat([df_1, df_2, df_3], axis=0)\n",
    "print(f\"Figurative results --- \\nShape: {df_fig.shape} \\n\\\n",
    "Ids Únicos: {df_fig['ID'].nunique()} \\n\\\n",
    "Diferença: {df_fig.shape[0] - df_fig['ID'].nunique() }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis Figurative\n",
    "\n",
    "### Duplicados\n",
    "\n",
    "Logo esses tbm fazem partes dos erros :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados--- \n",
      "Shape: (153, 5) \n",
      "Ids Únicos: 61 \n",
      "Diferença: 92\n"
     ]
    }
   ],
   "source": [
    "df_dup_fig = df_fig[df_fig.duplicated(subset='ID', keep=False)]\n",
    "print(f\"Duplicados--- \\nShape: {df_dup_fig.shape} \\n\\\n",
    "Ids Únicos: {df_dup_fig['ID'].nunique()} \\n\\\n",
    "Diferença: { df_dup_fig.shape[0] - df_dup_fig['ID'].nunique() }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figurative Erros--- \n",
      "Shape: (742, 5) \n",
      "Ids Únicos: 742 \n",
      "Diferença: 0\n"
     ]
    }
   ],
   "source": [
    "df_fig_resp = df_base[~df_base['ID'].isin(df_fig['ID'].unique())]\n",
    "print(f\"Figurative Erros--- \\nShape: {df_fig_resp.shape} \\n\\\n",
    "Ids Únicos: {df_fig_resp['ID'].nunique()} \\n\\\n",
    "Diferença: {df_fig_resp.shape[0] - df_fig_resp['ID'].nunique() }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figurative Erros --- \n",
      "Shape: (895, 8) \n",
      "Ids Únicos: 803 \n",
      "Diferença: 92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ORIGINAL</th>\n",
       "      <th>TOKENS_EST_ID</th>\n",
       "      <th>TOKENS_EST_ORIGINAL</th>\n",
       "      <th>TOTAL_TOKENS</th>\n",
       "      <th>FIGURATIVO</th>\n",
       "      <th>REESCRITO</th>\n",
       "      <th>RESULTADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>678Q1</td>\n",
       "      <td>A β-oxidação de uma molécula de ácido palmítico, CH3(CH2)14CO2H:</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                                          ORIGINAL  \\\n",
       "677  678Q1  A β-oxidação de uma molécula de ácido palmítico, CH3(CH2)14CO2H:   \n",
       "\n",
       "     TOKENS_EST_ID  TOKENS_EST_ORIGINAL  TOTAL_TOKENS FIGURATIVO REESCRITO  \\\n",
       "677            3.0                 35.0          38.0        NaN       NaN   \n",
       "\n",
       "    RESULTADO  \n",
       "677       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fig_error = pd.concat([df_fig_resp, df_dup_fig])\n",
    "print(f\"Figurative Erros --- \\nShape: {df_fig_error.shape} \\n\\\n",
    "Ids Únicos: {df_fig_error['ID'].nunique()} \\n\\\n",
    "Diferença: {df_fig_error.shape[0] - df_fig_error['ID'].nunique() }\")\n",
    "df_fig_error.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Figurative Results and Figurative Errors\n",
    "\n",
    "Esse é o resultado sem considerar os erros que houve no figurativo.\n",
    "\n",
    "Pois é com base nele que será enviado para a GLOSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fig_error.to_csv(path_base+\"02_\"+dataset+\"_figurative_error.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figurative Results --- \n",
      "Shape: (77023, 5) \n",
      "Ids Únicos: 77023 \n",
      "Diferença: 0\n"
     ]
    }
   ],
   "source": [
    "df_fig_results = df_fig[\n",
    "    ~df_fig['ID'].isin(df_fig_error['ID'].unique()) \n",
    "]\n",
    "print(f\"Figurative Results --- \\nShape: {df_fig_results.shape} \\n\\\n",
    "Ids Únicos: {df_fig_results['ID'].nunique()} \\n\\\n",
    "Diferença: {df_fig_results.shape[0] - df_fig_results['ID'].nunique() }\")\n",
    "df_fig_results.to_csv(path_base+\"03_\"+dataset+\"_figurative_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glosa Results\n",
    "\n",
    "Data Frame Base Glosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Glosa --- \n",
      "Shape: (77023, 5) \n",
      "Ids Únicos: 77023 \n",
      "Diferença: 0\n"
     ]
    }
   ],
   "source": [
    "df_base_glosa = pd.read_csv(path_base+\"04_\"+dataset+\"_to_gloss.csv\")\n",
    "\n",
    "# lembrar de tirar que são só os que estão no resultado do figurative\n",
    "df_base_glosa = df_base_glosa[ df_base_glosa['ID'].isin(df_fig_results['ID'])]\n",
    "\n",
    "print(f\"Base Glosa --- \\nShape: {df_base_glosa.shape} \\n\\\n",
    "Ids Únicos: {df_base_glosa['ID'].nunique()} \\n\\\n",
    "Diferença: {df_base_glosa.shape[0] - df_base_glosa['ID'].nunique() }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glosa results bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket---\n",
      "Total de IDs com sufixo 'Q1': 15272\n",
      "Total de IDs com sufixo 'C1': 15347\n",
      "Total de IDs com sufixo 'C2': 15268\n",
      "Total de IDs com sufixo 'C3': 15073\n",
      "Total de IDs com sufixo 'C4': 15200\n",
      "Total de IDs com sufixo 'C5': 0\n",
      "Total de IDs com sufixo 'C6': 0\n",
      "Total de IDs com sufixo 'C7': 0\n",
      "Total de IDs com sufixo 'C8': 0\n",
      "Total de IDs com sufixo 'C9': 0\n",
      "Total de IDs com sufixo 'C10': 0\n",
      "Total ids: 76160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(76155, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Bucket---\")\n",
    "content_bucket = read_file_txt(\"../DATASETS/METADATA/\"+\"glosa_\"+dataset+\"_to_gloss_response.txt\")\n",
    "count_ids(content_bucket, suffixes = [\"Q1\", \"C1\", \"C2\", 'C3', \"C4\", \"C5\", \"C6\", 'C7', \"C8\", \"C9\", \"C10\"])\n",
    "\n",
    "df_glo_1 = glosa_extrair_dados_para_dataframe_by_bucket(content_bucket) # 119642\n",
    "df_glo_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single---\n",
      "Total de IDs com sufixo 'Q1': 147\n",
      "Total de IDs com sufixo 'C1': 95\n",
      "Total de IDs com sufixo 'C2': 172\n",
      "Total de IDs com sufixo 'C3': 366\n",
      "Total de IDs com sufixo 'C4': 231\n",
      "Total de IDs com sufixo 'C5': 0\n",
      "Total de IDs com sufixo 'C6': 0\n",
      "Total de IDs com sufixo 'C7': 0\n",
      "Total de IDs com sufixo 'C8': 0\n",
      "Total de IDs com sufixo 'C9': 0\n",
      "Total de IDs com sufixo 'C10': 0\n",
      "Total ids: 1011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((790, 3), (221, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No caso do single é bom passar nos dois tanto no bucket quanto no single \n",
    "print(\"Single---\")\n",
    "content_single = read_file_txt(\"../DATASETS/METADATA/\"+\"glosa_last_\"+dataset+\"_to_gloss_single_response.txt\")\n",
    "count_ids(content_single, suffixes = [\"Q1\", \"C1\", \"C2\", 'C3', \"C4\", \"C5\", \"C6\", 'C7', \"C8\", \"C9\", \"C10\"])\n",
    "\n",
    "df_glo_2 = glosa_extrair_dados_para_dataframe_by_bucket(content_single)\n",
    "df_glo_3 = glosa_extrair_dados_para_dataframe_single_block(content_single)\n",
    "df_glo_2.shape, df_glo_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Glosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glosa Response --- \n",
      "Shape: (77021, 3) \n",
      "Ids Únicos: 77020 \n",
      "Diferença: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PT</th>\n",
       "      <th>GLOSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0Q1</td>\n",
       "      <td>Encontre o grau para a extensão de campo dada Q(sqrt(2), sqrt(3), sqrt(18)) sobre Q.</td>\n",
       "      <td>GRAU ENCONTRAR EXTENSÃO CAMPO Q RAIZ QUADRADA 2 RAIZ QUADRADA 3 RAIZ QUADRADA 18 SOBRE Q.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Q1</td>\n",
       "      <td>Seja p = (1, 2, 5, 4)(2, 3) em S_5 . Encontre o índice de &lt;p&gt; em S_5.</td>\n",
       "      <td>P 1 2 5 4 2 3 S5 ÍNDICE ENCONTRAR P S5.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  \\\n",
       "0  0Q1   \n",
       "1  1Q1   \n",
       "\n",
       "                                                                                     PT  \\\n",
       "0  Encontre o grau para a extensão de campo dada Q(sqrt(2), sqrt(3), sqrt(18)) sobre Q.   \n",
       "1                 Seja p = (1, 2, 5, 4)(2, 3) em S_5 . Encontre o índice de <p> em S_5.   \n",
       "\n",
       "                                                                                       GLOSA  \n",
       "0  GRAU ENCONTRAR EXTENSÃO CAMPO Q RAIZ QUADRADA 2 RAIZ QUADRADA 3 RAIZ QUADRADA 18 SOBRE Q.  \n",
       "1                                                    P 1 2 5 4 2 3 S5 ÍNDICE ENCONTRAR P S5.  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glosa_response = pd.concat([df_glo_1, df_glo_2, df_glo_3], axis=0)\n",
    "# o response, tem que ser só os que estão em figurative results tbm, pois eu estou fazendo essa validação\n",
    "# depois de ter vazado dado\n",
    "df_glosa_response = df_glosa_response[df_glosa_response['ID'].isin(df_fig_results['ID'].unique())]\n",
    "print(f\"Glosa Response --- \\nShape: {df_glosa_response.shape} \\n\\\n",
    "Ids Únicos: {df_glosa_response['ID'].nunique()} \\n\\\n",
    "Diferença: {df_glosa_response.shape[0] - df_glosa_response['ID'].nunique() }\")\n",
    "df_glosa_response.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glosa Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glosa results duplicados --- \n",
      "Shape: (2, 3) \n",
      "Ids Únicos: 1 \n",
      "Diferença: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PT</th>\n",
       "      <th>GLOSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50401</th>\n",
       "      <td>10814C1</td>\n",
       "      <td>prevalecer, porque o contrato escrito entre o proprietário e o paisagista teve o mesmo efeito legal de uma cessão válida para o filho.</td>\n",
       "      <td>CONTRATO ESCRITO PROPRIETÁRIO PAISAGISTA MESMO EFEITO LEGAL CESSÃO VÁLIDA FILHO PREVALECER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50417</th>\n",
       "      <td>10814C1</td>\n",
       "      <td>prevalecer, porque o contrato escrito entre o proprietário e o paisagista teve o mesmo efeito legal de uma cessão válida para o filho.</td>\n",
       "      <td>CONTRATO ESCRITO PROPRIETÁRIO PAISAGISTA MESMO EFEITO LEGAL CESSÃO VÁLIDA FILHO PREVALECER.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  \\\n",
       "50401  10814C1   \n",
       "50417  10814C1   \n",
       "\n",
       "                                                                                                                                           PT  \\\n",
       "50401  prevalecer, porque o contrato escrito entre o proprietário e o paisagista teve o mesmo efeito legal de uma cessão válida para o filho.   \n",
       "50417  prevalecer, porque o contrato escrito entre o proprietário e o paisagista teve o mesmo efeito legal de uma cessão válida para o filho.   \n",
       "\n",
       "                                                                                             GLOSA  \n",
       "50401  CONTRATO ESCRITO PROPRIETÁRIO PAISAGISTA MESMO EFEITO LEGAL CESSÃO VÁLIDA FILHO PREVALECER.  \n",
       "50417  CONTRATO ESCRITO PROPRIETÁRIO PAISAGISTA MESMO EFEITO LEGAL CESSÃO VÁLIDA FILHO PREVALECER.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup_glosa = df_glosa_response[df_glosa_response.duplicated(subset='ID', keep=False)]\n",
    "print(f\"Glosa results duplicados --- \\nShape: {df_dup_glosa.shape} \\n\\\n",
    "Ids Únicos: {df_dup_glosa['ID'].nunique()} \\n\\\n",
    "Diferença: {df_dup_glosa.shape[0] - df_dup_glosa['ID'].nunique() }\")\n",
    "df_dup_glosa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erros Glosa Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glosa erros --- \n",
      "Shape: (3, 5) \n",
      "Ids Únicos: 3 \n",
      "Diferença: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PT</th>\n",
       "      <th>TOKENS_EST_ID</th>\n",
       "      <th>TOKENS_EST_PT</th>\n",
       "      <th>TOTAL_TOKENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1868Q1</td>\n",
       "      <td>Quais das seguintes suposições são necessárias para mostrar a consistência, imparcialidade e eficiência do estimador OLS?\\n\\ni) $E(u_t) = 0$\\n\\nii) $\\\\text{Var}(u_t) = \\\\sigma^2$\\n\\niii) $\\\\text{Cov}(u_t, u_{t-j}) = 0 \\\\forall j$\\n\\niv) $u_t \\\\sim N(0, \\\\sigma^2)$</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  \\\n",
       "1115  1868Q1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                            PT  \\\n",
       "1115  Quais das seguintes suposições são necessárias para mostrar a consistência, imparcialidade e eficiência do estimador OLS?\\n\\ni) $E(u_t) = 0$\\n\\nii) $\\\\text{Var}(u_t) = \\\\sigma^2$\\n\\niii) $\\\\text{Cov}(u_t, u_{t-j}) = 0 \\\\forall j$\\n\\niv) $u_t \\\\sim N(0, \\\\sigma^2)$   \n",
       "\n",
       "      TOKENS_EST_ID  TOKENS_EST_PT  TOTAL_TOKENS  \n",
       "1115              4            141           145  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glosa_erros = df_base_glosa[ ~df_base_glosa['ID'].isin(df_glosa_response['ID'])]\n",
    "print(f\"Glosa erros --- \\nShape: {df_glosa_erros.shape} \\n\\\n",
    "Ids Únicos: {df_glosa_erros['ID'].nunique()} \\n\\\n",
    "Diferença: {df_glosa_erros.shape[0] - df_glosa_erros['ID'].nunique() }\")\n",
    "df_glosa_erros.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Glosa Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glosa_erros_complete = pd.concat([df_dup_glosa, df_glosa_erros])\n",
    "df_glosa_erros_complete.to_csv(path_base+\"05_\"+dataset+\"_gloss_error.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glosa Final --- \n",
      "Shape: (77019, 3) \n",
      "Ids Únicos: 77019 \n",
      "Diferença: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PT</th>\n",
       "      <th>GLOSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0Q1</td>\n",
       "      <td>Encontre o grau para a extensão de campo dada Q(sqrt(2), sqrt(3), sqrt(18)) sobre Q.</td>\n",
       "      <td>GRAU ENCONTRAR EXTENSÃO CAMPO Q RAIZ QUADRADA 2 RAIZ QUADRADA 3 RAIZ QUADRADA 18 SOBRE Q.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  \\\n",
       "0  0Q1   \n",
       "\n",
       "                                                                                     PT  \\\n",
       "0  Encontre o grau para a extensão de campo dada Q(sqrt(2), sqrt(3), sqrt(18)) sobre Q.   \n",
       "\n",
       "                                                                                       GLOSA  \n",
       "0  GRAU ENCONTRAR EXTENSÃO CAMPO Q RAIZ QUADRADA 2 RAIZ QUADRADA 3 RAIZ QUADRADA 18 SOBRE Q.  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se tiver erro, descomentar essa parte\n",
    "df_glosa_final = df_glosa_response[ ~df_glosa_response['ID'].isin(df_glosa_erros_complete['ID'].unique())]\n",
    "\n",
    "print(f\"Glosa Final --- \\nShape: {df_glosa_final.shape} \\n\\\n",
    "Ids Únicos: {df_glosa_final['ID'].nunique()} \\n\\\n",
    "Diferença: {df_glosa_final.shape[0] - df_glosa_final['ID'].nunique() }\")\n",
    "df_glosa_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glosa_response.to_csv(path_base+\"06_\"+dataset+\"_gloss_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data Frame to Original Structure\n",
    "\n",
    "Agora vamos pegar esse dataframe de resultados e voltar para o estado original de:\n",
    "\n",
    "Questão, Resposta 1, Resposta 2, Resposta 3 ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado glosa---\n",
      " shape: (77021, 4)\n",
      " ids únicos: 15549\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CLASS_TYPE</th>\n",
       "      <th>ID</th>\n",
       "      <th>Q1</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAU ENCONTRAR EXTENSÃO CAMPO Q RAIZ QUADRADA 2 RAIZ QUADRADA 3 RAIZ QUADRADA 18 SOBRE Q.</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>4</td>\n",
       "      <td>DOIS.</td>\n",
       "      <td>SEIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "CLASS_TYPE  ID  \\\n",
       "0            0   \n",
       "\n",
       "CLASS_TYPE                                                                                         Q1  \\\n",
       "0           GRAU ENCONTRAR EXTENSÃO CAMPO Q RAIZ QUADRADA 2 RAIZ QUADRADA 3 RAIZ QUADRADA 18 SOBRE Q.   \n",
       "\n",
       "CLASS_TYPE    C1 C2     C3    C4  C5  C6  C7  C8  C9  C10  \n",
       "0           ZERO  4  DOIS.  SEIS NaN NaN NaN NaN NaN  NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = processar_glosa_to_original_format(df_glosa_response)\n",
    "df_result.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado glosa---\n",
      " shape: (77021, 4)\n",
      " ids únicos: 15549\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CLASS_TYPE</th>\n",
       "      <th>ID</th>\n",
       "      <th>Q1</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15548</th>\n",
       "      <td>126601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EGOCENTRISMO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "CLASS_TYPE      ID   Q1   C1            C2   C3   C4  C5  C6  C7  C8  C9  C10\n",
       "15548       126601  NaN  NaN  EGOCENTRISMO  NaN  NaN NaN NaN NaN NaN NaN  NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = processar_glosa_to_original_format(df_glosa_response)\n",
    "df_result.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join with original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id           subject  is_duplicate\n",
       "0            0  abstract_algebra         False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(path_base+\"0_\"+dataset+\".csv\")\n",
    "# mllu pro : ['question_id', 'answer', 'answer_index','category', 'src']\n",
    "df_to_join = df_original[['question_id', 'subject', 'is_duplicate' ]].copy()\n",
    "df_to_join.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_duplicate\n",
       "False    15168\n",
       "True       405\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15573, 10), (15549, 12), 24)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.shape, df_result.shape, df_original.shape[0] - df_result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15548, 15)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.merge(df_result, df_to_join, left_on='ID', right_on='question_id')\n",
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_nulos_individuais(df_or, df_re):\n",
    "\n",
    "    df_resposta = []\n",
    "\n",
    "    for id_value in df_re['ID'].unique():\n",
    "\n",
    "        linha_result = df_re[df_re['ID'] == id_value]\n",
    "        linha_original = df_or[df_or['question_id'] == id_value]\n",
    "\n",
    "        if linha_original.empty:\n",
    "            continue\n",
    "\n",
    "        valido = True \n",
    "        for num in range(1, 5): # 11 quando pro\n",
    "            coluna_C = f\"C{num}\"\n",
    "            coluna_choice = f\"choice_{num}\"\n",
    "            \n",
    "            if (linha_result[coluna_C].isnull().values[0] and \n",
    "                not linha_original[coluna_choice].isnull().values[0]) or \\\n",
    "               (not linha_result[coluna_C].isnull().values[0] and \n",
    "                linha_original[coluna_choice].isnull().values[0]):\n",
    "                valido = False\n",
    "                break\n",
    "\n",
    "   \n",
    "        if valido:\n",
    "            df_resposta.append(linha_result)\n",
    "\n",
    "    df_resposta = pd.concat(df_resposta, ignore_index=True) if df_resposta else pd.DataFrame()\n",
    "    \n",
    "    return df_resposta\n",
    "\n",
    "df_validados = verificar_nulos_individuais(df_original, df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15360, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235,\n",
       " 677    678\n",
       " 893    896\n",
       " Name: ID, dtype: int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#questions NULOS\n",
    "ids_nulos = df_result[df_result['Q1'].isnull()]['ID']\n",
    "len(ids_nulos), ids_nulos[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15136, 15)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validados = df_validados[~df_validados['ID'].isin(ids_nulos)]\n",
    "df_validados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validados.to_csv(path_base+\"07_\"+dataset+\"_pre_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tradutor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
